{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "123575d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 189ms/step - accuracy: 0.0926 - loss: 2.5112 - val_accuracy: 0.0084 - val_loss: 1.8965\n",
      "Epoch 2/30\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 177ms/step - accuracy: 0.1158 - loss: 2.2278 - val_accuracy: 0.0719 - val_loss: 1.8471\n",
      "Epoch 3/30\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 172ms/step - accuracy: 0.1476 - loss: 2.0800 - val_accuracy: 0.4854 - val_loss: 1.7909\n",
      "Epoch 4/30\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 180ms/step - accuracy: 0.2041 - loss: 1.9834 - val_accuracy: 0.3635 - val_loss: 1.7621\n",
      "Epoch 5/30\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 172ms/step - accuracy: 0.2597 - loss: 1.9110 - val_accuracy: 0.3108 - val_loss: 1.7754\n",
      "Epoch 6/30\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 175ms/step - accuracy: 0.3197 - loss: 1.8321 - val_accuracy: 0.3635 - val_loss: 1.7410\n",
      "Epoch 7/30\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 172ms/step - accuracy: 0.3642 - loss: 1.7721 - val_accuracy: 0.3076 - val_loss: 1.7602\n",
      "Epoch 8/30\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 179ms/step - accuracy: 0.4017 - loss: 1.7269 - val_accuracy: 0.2936 - val_loss: 1.7508\n",
      "Epoch 9/30\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 178ms/step - accuracy: 0.4220 - loss: 1.6916 - val_accuracy: 0.3103 - val_loss: 1.7152\n",
      "Epoch 10/30\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 171ms/step - accuracy: 0.4435 - loss: 1.6501 - val_accuracy: 0.3604 - val_loss: 1.6806\n",
      "Epoch 11/30\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 179ms/step - accuracy: 0.4493 - loss: 1.6122 - val_accuracy: 0.3633 - val_loss: 1.6300\n",
      "Epoch 12/30\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 180ms/step - accuracy: 0.4660 - loss: 1.5694 - val_accuracy: 0.4351 - val_loss: 1.6072\n",
      "Epoch 13/30\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 180ms/step - accuracy: 0.4784 - loss: 1.5272 - val_accuracy: 0.4475 - val_loss: 1.5215\n",
      "Epoch 14/30\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 172ms/step - accuracy: 0.4807 - loss: 1.4999 - val_accuracy: 0.5045 - val_loss: 1.4513\n",
      "Epoch 15/30\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 170ms/step - accuracy: 0.4830 - loss: 1.4644 - val_accuracy: 0.5150 - val_loss: 1.3929\n",
      "Epoch 16/30\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 177ms/step - accuracy: 0.4919 - loss: 1.4133 - val_accuracy: 0.5107 - val_loss: 1.4040\n",
      "Epoch 17/30\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 175ms/step - accuracy: 0.5057 - loss: 1.3974 - val_accuracy: 0.5072 - val_loss: 1.3529\n",
      "Epoch 18/30\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 169ms/step - accuracy: 0.4925 - loss: 1.3831 - val_accuracy: 0.5068 - val_loss: 1.3127\n",
      "Epoch 19/30\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 167ms/step - accuracy: 0.4912 - loss: 1.3578 - val_accuracy: 0.5067 - val_loss: 1.2929\n",
      "Epoch 20/30\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 193ms/step - accuracy: 0.5043 - loss: 1.3337 - val_accuracy: 0.5108 - val_loss: 1.2509\n",
      "Epoch 21/30\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 180ms/step - accuracy: 0.4992 - loss: 1.3138 - val_accuracy: 0.5100 - val_loss: 1.2536\n",
      "Epoch 22/30\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 169ms/step - accuracy: 0.5178 - loss: 1.2889 - val_accuracy: 0.5088 - val_loss: 1.2416\n",
      "Epoch 23/30\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 173ms/step - accuracy: 0.5000 - loss: 1.2847 - val_accuracy: 0.5112 - val_loss: 1.2497\n",
      "Epoch 24/30\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 178ms/step - accuracy: 0.5010 - loss: 1.2762 - val_accuracy: 0.5112 - val_loss: 1.2195\n",
      "Epoch 25/30\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 183ms/step - accuracy: 0.5100 - loss: 1.2548 - val_accuracy: 0.5128 - val_loss: 1.2225\n",
      "Epoch 26/30\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 177ms/step - accuracy: 0.5157 - loss: 1.2315 - val_accuracy: 0.5122 - val_loss: 1.2156\n",
      "Epoch 27/30\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 182ms/step - accuracy: 0.5145 - loss: 1.2406 - val_accuracy: 0.5125 - val_loss: 1.2064\n",
      "Epoch 28/30\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 175ms/step - accuracy: 0.5119 - loss: 1.2249 - val_accuracy: 0.5123 - val_loss: 1.1961\n",
      "Epoch 29/30\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 173ms/step - accuracy: 0.5210 - loss: 1.2142 - val_accuracy: 0.5098 - val_loss: 1.1812\n",
      "Epoch 30/30\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 182ms/step - accuracy: 0.5148 - loss: 1.2010 - val_accuracy: 0.5127 - val_loss: 1.1819\n",
      "pérdida de prueba: 1.1812\n",
      "precisión de la prueba: 0.5098\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "\n",
    "data = pd.read_csv('covidata.csv')\n",
    "data.replace([97, 98, 99, '9999-99-99'], np.nan, inplace=True)\n",
    "data.fillna(data.mode().iloc[0], inplace=True)\n",
    "data.drop(['USMER', 'MEDICAL_UNIT', 'DATE_DIED'], axis=1, inplace=True)\n",
    "data = pd.get_dummies(data, columns=['SEX', 'PATIENT_TYPE'], drop_first=True)\n",
    "\n",
    "data = pd.read_csv('covidata.csv')\n",
    "data.replace([97, 98, 99, '9999-99-99'], np.nan, inplace=True)\n",
    "data.fillna(data.mode().iloc[0], inplace=True)\n",
    "data.drop(['USMER', 'MEDICAL_UNIT', 'DATE_DIED'], axis=1, inplace=True)\n",
    "data = pd.get_dummies(data, columns=['SEX', 'PATIENT_TYPE'], drop_first=True)\n",
    "\n",
    "#variables\n",
    "X = data.drop(['CLASIFFICATION_FINAL'], axis=1)\n",
    "y = data['CLASIFFICATION_FINAL'] - data['CLASIFFICATION_FINAL'].min()\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled = X_scaled.reshape((X_scaled.shape[0], X_scaled.shape[1], 1))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=y.nunique())\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=y.nunique())\n",
    "\n",
    "#tamaño para pruebas\n",
    "X_train_small = X_train[:5000]\n",
    "y_train_small = y_train[:5000]\n",
    "\n",
    "#modelo LSTM\n",
    "model = Sequential([\n",
    "    Input(shape=(X_train.shape[1], 1)),\n",
    "    LSTM(16, return_sequences=True),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),\n",
    "    LSTM(8),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),\n",
    "    Dense(y.nunique(), activation='softmax')\n",
    "])\n",
    "\n",
    "#compilacion y entrenamiento con early stopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "model.compile(optimizer=Adam(learning_rate=0.0005), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train_small, y_train_small, epochs=30, batch_size=128, validation_data=(X_test, y_test), callbacks=[early_stop], verbose=1)\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'pérdida de prueba: {loss:.4f}')\n",
    "print(f'precisión de la prueba: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabc9dcf-c519-478f-a6fe-b1995992aa1a",
   "metadata": {},
   "source": [
    "# Enfoque\n",
    "\n",
    "El modelo se basó en la clasificación de casos COVID-19. La estructura del modelo es una red LSTM bidimensional, con dos capas LSTM de 128 y 64 unidades. Dentro de este, mediante la moda, reemplacé valores vacíos con valores estimados. Omití columnas innecesarias y transformé las variables categóricas en representaciones numéricas mediante one-hot. Los datos de entrada los escalé con MinMaxScaler para dar estabilidad y eficiencia al entrenamiento. Incorporé Batch Normalization para estabilizar el modelo y Dropout para disminuir el sobreajuste. Y para la capa de salida usé softmax para la clasificación multiclase.\n",
    "Usé la función de perdida categorial_crossentropy y el optimizador Adam con una tasa de aprendizaje 0.0005. El modelo se entrena por 100 épocas con un tamaño de “lote” de 64 y por última se evalúa empleando precisión en el conjunto de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad17c1f-6d0a-4b08-bd64-7a85f5298cfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
